![Github Watchers](https://img.shields.io/github/watchers/alokssingh/Show-and-Tell-Image-caption-using-Visual-Attention-Keras-Implementation?color=brightgreen)
![GitHub stars](https://img.shields.io/github/stars/alokssingh/Show-and-Tell-Image-caption-using-Visual-Attention-Keras-Implementation?color=brightgreen)
![GitHub forks](https://img.shields.io/github/forks/alokssingh/Show-and-Tell-Image-caption-using-Visual-Attention-Keras-Implementation?color=brightgreen&label=Fork)


# Show-and-Tell-Image-caption-using-Visual-Attention-Keras-Implementation
This repository contations the keras implementation of Show and Tell Visual Attention visual attnetion for image captioning,

More Examples will be uploaded soon

#Requirements

#Keras 2.3.1

#Tensorflow 1.15.2
             This implementation is tested on caption generation.       


https://github.com/zimmerrol/keras-utility-layer-collection/blob/e0a888277ee0121b88c8541ff7642e4615a76ce1/kulc/attention.py#L38
                                                                                                                               
https://github.com/alokssingh/imcap_keras/blob/master/imcap/layers/lstm_sent.py                                                
https://arxiv.org/pdf/1502.03044.pdfv                                                                                          
  If you use help of this implementataion please cite us.                                                                      
